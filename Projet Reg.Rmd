---
title: "statRregression_IA-M1DA2"
author: "Hady COULIBALY"
date: "2024-09-29"
output:
  html_document:
    df_print: paged
  pdf_document: default
  word_document: default
---


```{r}
#install.packages("corrplot")
#install.packages("caTools")
#install.packages("AER")
#install.packages("forecast")
#install.packages("mgcv")
#install.packages("ggplot2")
#install.packages("dplyr")
#install.packages("car")
```




```{r}
data_day = read.table("C:/Users/Hady COULIBALY/Desktop/M1-DA/Regression/Projet/day.csv", sep = ",", header = TRUE)
```

```{r}
data_hour = read.table("C:/Users/Hady COULIBALY/Desktop/M1-DA/Regression/Projet/hour.csv", sep = ",", header = TRUE)

```

```{r}
str(data_day)
str(data_hour)
```




# Prétraitement des données




```{r}
# Valeur manquante
sum(is.na(data_day))
colSums(is.na(data_day))
```

### Transformation des variables


```{r}
data_day$dteday = as.Date(data_day$dteday)
data_hour$dteday = as.Date(data_hour$dteday)
data_hour$hr = factor(data_hour$hr, levels = 0:23)
data_day$season = factor(data_day$season, 
                           levels = c(1, 2, 3, 4), 
                           labels = c("Printemps", "Été", "Automne", "Hiver"))

data_day$mnth = factor(data_day$mnth, 
                         levels = 1:12, 
                         labels = month.name)

data_day$weekday = factor(data_day$weekday, 
                            levels = 0:6, 
                            labels = c("Dimanche", "Lundi", "Mardi", "Mercredi", 
                                       "Jeudi", "Vendredi", "Samedi"))

data_day$weathersit = factor(data_day$weathersit, 
                               levels = c(1, 2, 3, 4), 
                               labels = c("Ciel dégagé", "Brouillard", "Pluie légère", "Fortes précipitations"))

data_day$holiday = factor(data_day$holiday, 
                            levels = c(0, 1), 
                            labels = c("Non", "Oui"))

data_day$workingday = factor(data_day$workingday, 
                               levels = c(0, 1), 
                               labels = c("Non", "Oui"))

str(data_day)
```





# Partie 1:	Analyse exploratoire des données 



#### ○	Visualiser la distribution du nombre de locations de vélos par heure

```{r}
library(ggplot2)
library(dplyr)

ggplot(data_hour, aes(x = hr, y = cnt)) +
  geom_histogram(stat = "identity", fill = "steelblue") +
  labs(title = "Distribution des locations de vélos par heure", x = "Heure de la journée", y = "Nombre de locations") +
  theme_minimal()
```




#### ○	Explorer les relations entre le nombre de locations et les différentes variables explicatives

```{r}
library(corrplot)
matrice_cor = cor(data_day[, c("cnt", "temp", "atemp", "hum", "windspeed", "casual","registered" )], use = "complete.obs")

print(matrice_cor)
```

```{r}
library(corrplot)

corrplot(matrice_cor, method = "color", type = "upper", 
         tl.col = "black", tl.srt = 45, addCoef.col = "black", 
         number.cex = 0.7, number.digits = 2)
```





```{r}

par(mfcol = c(1,2))

boxplot(data_day$cnt ~ data_day$weekday, main= "Nbr de locations par jour",xlab=" Jour de la semaine ",ylab = "Nbrlocations", col= "lightgreen")

boxplot(data_day$cnt ~ data_day$mnth, main= "Nbr de locations par mois",xlab=" Mois ",ylab = "Nbrlocations", col= "orange")

```

```{r}
par(mfcol = c(1,2))

boxplot(data_day$cnt ~ data_day$season, main= "Nbr de locations par Saison", xlab = "saison",ylab = "Nbrlocations", col="lightgreen")

boxplot(data_day$cnt ~ data_day$holiday, main= "Nbr de locations par jour ferié ou non",xlab=" jour ferié ou non ",ylab = "Nbrlocations", col= "orange")
```





#### ○	Identifier des tendances saisonnières ou temporelles


```{r}
library(ggplot2)
# Moyenne des locations par saison
seasonal_trends = data_day %>%
  group_by(season) %>%
  summarise(mean_cnt = mean(cnt, na.rm = TRUE))

# Visualisation de la demande moyenne par saison
ggplot(seasonal_trends, aes(x = season, y = mean_cnt, fill = season)) +
  geom_bar(stat = "identity") +
  labs(title = "Demande moyenne de vélos selon les saisons", x = "Saison", y = "Nombre moyen de locations") +
  theme_minimal()

```



```{r}
# Relation entre le nombre de locations et la température
ggplot(data_day, aes(x=temp, y=cnt)) +
  geom_point(alpha=0.5) +
  geom_smooth(method="lm", se=FALSE, color="red") +
  labs(title="Relation entre la température et le nombre de locations", x="Température normalisée", y="Nombre de locations") +
  theme_minimal()
```


```{r}
# Relation entre le nombre de locations et le jour de la semaine
ggplot(data_day, aes(x=weekday, y=cnt)) +
  geom_boxplot(aes(group=weekday)) +
  labs(title="Nombre de locations en fonction du jour de la semaine", x="Jour de la semaine", y="Nombre de locations") +
  theme_minimal()
```




```{r}
# Nombre de locations par mois
ggplot(data_day, aes(x=mnth, y=cnt)) +
  geom_boxplot(aes(group=mnth)) +
  labs(title="Nombre de locations par mois", x="Mois", y="Nombre de locations") +
  theme_minimal()

```








# Partie 2:  Modélisation



Le projet vise à modéliser la demande de vélos en libre-service en fonction de plusieurs variables explicatives comme la météo, le jour de la semaine, la saison, etc. Le nombre de locations de vélos est une variable de comptage (une variable entière non négative) et demande une approche spécifique pour sa modélisation.


Dans le cadre de cette étude, ce n'est pas pertinent d'utiliser le modèle de regression linéaire pour la réduction car elle  suppose que la variable dépendante suit une distribution normale et que les résidus sont également normalement distribués, ce qui n'est pas adapté pour une variable de comptage non négative comme le nombre de locations (cnt).

Les modèles les plus appropriés pour des données de comptage sont:

1) Régression de Poisson
2) Régression binomiale négative 
3) GAM (Generalized Additive Model)
4) Modèles temporels (SARIMA)



###### Diviser le jeu de donnée en ensembles de donnée d'entraînement et de test


```{r}
#install.packages("caTools")
library(caTools)
```


```{r}

set.seed(123)

# Diviser les données en 80% pour l'entraînement et 20% pour le test
split = sample.split(data_day$cnt, SplitRatio = 0.8)

# Créer les ensembles d'entraînement et de test
train_data = subset(data_day, split == TRUE)
test_data = subset(data_day, split == FALSE)

```



### Modèle de Poisson de base


```{r}
poisson_model = glm(cnt ~ temp + atemp + hum + windspeed + season + yr + mnth + weekday + holiday , 
                     data = train_data, family = poisson(link = "log"))
summary(poisson_model)

```





```{r}
# Verification de la dispersion avec la fonction dispersiontest()
library(AER)

# Test de surdispersion
dispersiontest(poisson_model)

```



```{r}
# Vérification de la distribution  avec le ratio variance/moyenne
mean_cnt = mean(data_day$cnt)
var_cnt = var(data_day$cnt)

mean_cnt  # Moyenne
var_cnt   # Variance

# Vérification du ratio variance / moyenne
var_cnt / mean_cnt
```




### Modèle binomial négatif

Si les données montrent de la surdispersion (la variance est plus grande que la moyenne), la régression binomiale négative est plus adaptée.Nous avons dejà verifier cette surdispersion à l'aide du Test de dispersion et de la ratio de variance/moyenne ci-dessus. 


Nous pouvons maintenant ajuster notre modèle sur l'ensemble des données d'entraînement :

```{r}
library(dplyr)
#install.packages("MASS")
#install.packages("MASS", repos = "http://cran.us.r-project.org")

library(MASS)
```


```{r}
# Ajuster le modèle binomial négatif sur l'ensemble d'entraînement
nb_model_train = glm.nb(cnt ~  + atemp + hum + windspeed + season + yr + mnth + weekday + holiday, 
                         data = train_data)

```

```{r}
summary(nb_model_train)
```




### Modèle GAM (Generalized Additive Model)

Ce modèle permet de capturer des relations non linéaires à l’aide de splines. Si des relations non linéaires sont présentes entre la variable de réponse et les prédicteurs, ce modèle devient pertinent.


```{r}
library(mgcv)
# Modèle GAM pour capturer des relations non linéaires
gam_model = gam(cnt ~ s(temp) + s(hum) + s(windspeed) + season + yr + mnth + weekday + holiday + workingday, 
                 data = train_data, family = poisson(link = "log"))
summary(gam_model)

```




### Modèle ARIMA simple

Pour capturer des dépendances temporelles dans les données, un modèle SARIMA peut être utile, bien qu'il soit principalement utilisé dans des séries chronologiques pures.

```{r}
library(forecast)
sarima_model = auto.arima(data_day$cnt, seasonal = TRUE)
summary(sarima_model)

```




### Comparaison des performances des différents modèles 


```{r}
# Comparer les modèles avec le test du rapport de vraisemblance
lrtest = lmtest::lrtest(poisson_model, nb_model_train)

# Afficher les résultats du test du rapport de vraisemblance
lrtest

```



```{r}
# Comparer les modèles gam_model et nb_model_train avec le test du rapport de vraisemblance
lrtest = lmtest::lrtest(gam_model, nb_model_train)

# Afficher les résultats du test du rapport de vraisemblance
lrtest
```





###### Verification de l'hyphothèse de multiconéarité


```{r}
library("car")
vif(nb_model_train)

```



```{r}
# Prédictions sur l'ensemble de test
pred_test = predict(nb_model_train, newdata = test_data, type = "response")

# Comparer les prédictions avec les valeurs réelles (par exemple avec RMSE ou MAE)
rmse_test = sqrt(mean((pred_test - test_data$cnt)^2))
print(paste("RMSE sur l'ensemble de test:", rmse_test))

```

```{r}
mean(data_day$cnt)
```



# Partie 3: Prédictions et recommandations 


###### Prédictions

Création d'un nouveau data frame pour la préduction

```{r}
new_data=data.frame(
  atemp = c(0.35, 0.25, 0.15),  
  hum = c(0.6, 0.8, 0.4),  
  windspeed = c(0.2, 0.3, 0.1), 
  season = factor(c("Été", "Hiver", "Printemps"), 
                  levels = c("Printemps", "Été", "Automne", "Hiver")),
  yr = c(1, 1, 0),  
  mnth = factor(c(6, 1, 3), 
                 levels = 1:12, 
                 labels = month.name),  
  weekday = factor(c("Lundi", "Mercredi", "Vendredi"), 
                   levels = c("Dimanche", "Lundi", "Mardi", "Mercredi", "Jeudi", "Vendredi", "Samedi")),
  holiday = factor(c("Non", "Non", "Oui"), 
                   levels = c("Non", "Oui")) 
  
)

```
 


```{r}
# Préduction
predictions = predict(nb_model_train, newdata = new_data, type = "response")

print(predictions)

```


